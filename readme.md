ğŸ“„ Phase 3 â€“ Document Processing (Multimodal RAG)
ğŸ“Œ Overview

This phase focuses on document processing for a multimodal Retrieval-Augmented Generation (RAG) system. The objective is to extract structured information from technical manuals, including text, images, and metadata, and prepare them for downstream embedding and retrieval stages.

The implementation follows a practical, code-first approach, ensuring real-world applicability rather than theoretical concepts.

ğŸ¯ Phase Objectives

Parse PDFs containing text and images

Chunk extracted text for efficient retrieval

Maintain metadata to preserve document structure

Link images with their relevant text sections

Prepare clean, structured outputs for multimodal embedding

ğŸ“‚ Project Structure
PDF PARSING/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ manuals/              # Input PDF manuals
â”‚   â”œâ”€â”€ extracted_text/       # Raw extracted text
â”‚   â”œâ”€â”€ extracted_images/     # Images extracted from PDFs
â”‚   â”œâ”€â”€ chunks/               # Text chunks for retrieval
â”‚   â””â”€â”€ metadata/             # Metadata and image-text links
â”‚
â”œâ”€â”€ pdf_parser.py             # PDF parsing (text + images)
â”œâ”€â”€ text_chunker.py           # Text chunking logic
â”œâ”€â”€ metadata_and_linking.py   # Metadata generation & image-text linking
â””â”€â”€ README.md

ğŸ”¹ Phase 3 Tasks Breakdown
1ï¸âƒ£ PDF Parsing (Text + Images)

Extracts text and images from technical manuals

Saves text and images separately for processing

Supports real-world manuals with mixed content

Output:

Extracted text files

Extracted image files

2ï¸âƒ£ Text Chunking

Splits large text into manageable chunks

Improves retrieval accuracy in RAG systems

Preserves semantic meaning across chunks

Output:

Chunked text files stored per document

3ï¸âƒ£ Metadata & Imageâ€“Text Linking

Generates structured metadata for text chunks

Links images to relevant text using document-level association

Maintains layout and contextual consistency

Output:

text_metadata.json

image_text_links.json

â–¶ï¸ How to Run the Phase 3 Pipeline
Step 1: Place Manuals
data/manuals/

Step 2: Run PDF Parsing
python pdf_parser.py

Step 3: Run Text Chunking
python text_chunker.py

Step 4: Generate Metadata & Linking
python metadata_and_linking.py

ğŸ§ª Practical Testing

Tested using sample technical manuals containing both text and images

Verified correct extraction of text, images, and metadata

Confirmed proper linkage between visual and textual components

ğŸš€ Outcome

By the end of Phase 3:

Documents are fully structured

Visual and textual information is preserved

Data is ready for multimodal embedding and retrieval (Phase 4)

ğŸ”œ Next Phase

Phase 4 â€“ Multimodal Embeddings

CLIP/SigLIP textâ€“image alignment

Image caption generation

Imageâ€“text similarity search

ğŸ§  Technologies Used

Python

PDF processing libraries

JSON for structured metadata storage

ğŸ‘¤ Author

Chamith Shanaka Samarasinghe
AI/ML Intern â€“ JW Infotech