#Multimodal RAG Capstone Project

This repository documents the **endâ€‘toâ€‘end implementation of a Multimodal Retrievalâ€‘Augmented Generation (RAG) system**, developed as a final capstone project. The project is organized into **six progressive phases**, each building toward a productionâ€‘ready AI system capable of understanding and answering questions from text and images.

The approach is **practical, codeâ€‘first, and industryâ€‘oriented**, focusing on realâ€‘world implementation rather than theoretical concepts.

---

## ğŸ“Œ Phase 1 â€“ Project Setup & Environment Configuration

### ğŸ“„ Overview

Phase 1 establishes the foundation for the Multimodal RAG system. This phase focuses on project structure, environment setup, dependency management, and validating that the development environment is ready for subsequent phases.

### ğŸ¯ Phase Objectives

* Create a clean, modular project structure
* Set up Python virtual environment
* Install required dependencies
* Validate basic script execution

### ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ logs/
â”œâ”€â”€ rag_pipeline/
â”œâ”€â”€ api.py
â”œâ”€â”€ logger_config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### â–¶ï¸ How to Run Phase 1

```bash
python --version
pip install -r requirements.txt
python -c "print('Environment Ready')"
```

### ğŸš€ Outcome

* Development environment successfully configured
* Project structure ready for incremental development

---

## ğŸ“Œ Phase 2 â€“ Textâ€‘Only RAG Pipeline

### ğŸ“„ Overview

This phase implements a **basic Retrievalâ€‘Augmented Generation pipeline** using text documents only. It validates the core RAG workflow before introducing multimodal data.

### ğŸ¯ Phase Objectives

* Load and preprocess text documents
* Generate embeddings for text
* Store embeddings in a vector database
* Retrieve relevant chunks for a query
* Generate answers using an LLM

### ğŸ“‚ Key Files

```
rag_pipeline/
â”œâ”€â”€ text_loader.py
â”œâ”€â”€ text_chunker.py
â”œâ”€â”€ embeddings.py
â”œâ”€â”€ vector_store.py
â””â”€â”€ rag_text_only.py
```

### â–¶ï¸ How to Run Phase 2

```bash
python rag_pipeline/rag_text_only.py
```

### ğŸš€ Outcome

* Functional textâ€‘only RAG pipeline
* Validated retrieval + generation flow

---

## ğŸ“Œ Phase 3 â€“ Document Processing (Multimodal RAG)

### ğŸ“„ Overview

This phase focuses on **document processing for multimodal inputs**. Text, images, and metadata are extracted from technical manuals and prepared for downstream embedding and retrieval.

### ğŸ¯ Phase Objectives

* Parse PDFs containing text and images
* Chunk extracted text
* Preserve document metadata
* Link images with relevant text sections

### ğŸ“‚ Project Structure

```
PDF_PARSING/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ manuals/
â”‚   â”œâ”€â”€ extracted_text/
â”‚   â”œâ”€â”€ extracted_images/
â”‚   â”œâ”€â”€ chunks/
â”‚   â””â”€â”€ metadata/
â”‚
â”œâ”€â”€ pdf_parser.py
â”œâ”€â”€ text_chunker.py
â”œâ”€â”€ metadata_and_linking.py
â””â”€â”€ README.md
```

### â–¶ï¸ How to Run Phase 3

```bash
python pdf_parser.py
python text_chunker.py
python metadata_and_linking.py
```

### ğŸš€ Outcome

* Fully structured multimodal documents
* Textâ€“image relationships preserved

---

## ğŸ“Œ Phase 4 â€“ Multimodal Embeddings

### ğŸ“„ Overview

This phase converts **text and images into a shared embedding space** using multimodal models, enabling crossâ€‘modal retrieval.

### ğŸ¯ Phase Objectives

* Generate embeddings for text chunks
* Generate embeddings for images
* Align text and image representations
* Store embeddings in a vector database

### ğŸ“‚ Key Files

```
rag_pipeline/
â”œâ”€â”€ multimodal_embeddings.py
â”œâ”€â”€ image_encoder.py
â”œâ”€â”€ text_encoder.py
â””â”€â”€ vector_store.py
```

### â–¶ï¸ How to Run Phase 4

```bash
python rag_pipeline/multimodal_embeddings.py
```

### ğŸš€ Outcome

* Text and images embedded in a unified vector space
* Ready for multimodal retrieval

---

## ğŸ“Œ Phase 5 â€“ Multimodal RAG Pipeline

### ğŸ“„ Overview

This phase integrates **retrieval and generation across both text and images**, completing the multimodal RAG logic.

### ğŸ¯ Phase Objectives

* Retrieve relevant text and images for a query
* Combine multimodal context
* Generate grounded responses using LLM

### ğŸ“‚ Key Files

```
rag_pipeline/
â”œâ”€â”€ retriever.py
â”œâ”€â”€ multimodal_rag.py
â””â”€â”€ answer_generator.py
```

### â–¶ï¸ How to Run Phase 5

```bash
python rag_pipeline/multimodal_rag.py
```

### ğŸš€ Outcome

* Endâ€‘toâ€‘end multimodal RAG pipeline
* Accurate responses using text + images

---

## ğŸ“Œ Phase 6 â€“ API, Logging & Final Integration (Capstone)

### ğŸ“„ Overview

The final phase exposes the Multimodal RAG system via a **FastAPI service**, adds structured logging, and prepares the project for demonstration and evaluation.

### ğŸ¯ Phase Objectives

* Build REST API using FastAPI
* Implement structured logging
* Add health checks
* Enable realâ€‘time query handling

### ğŸ“‚ Key Files

```
api.py
logger_config.py
rag_pipeline/
â””â”€â”€ answer_question.py
```

### â–¶ï¸ How to Run Phase 6

```bash
uvicorn api:app --reload
```

### ğŸ”— Available Endpoints

* `POST /ask` â€“ Query the Multimodal RAG system
* `GET /health` â€“ System health check
* `GET /docs` â€“ Interactive Swagger UI

### ğŸš€ Outcome

* Productionâ€‘ready Multimodal RAG API
* Fully logged and testable system

---

## ğŸ§ª Testing & Validation

* Tested with real technical manuals
* Verified text and image retrieval
* Confirmed API responses and logging

---

## ğŸ§  Technologies Used

* Python
* FastAPI
* Vector Databases (Milvus)
* Multimodal Embedding Models
* LLMs (via API)
* PDF Processing Libraries

---

## ğŸ‘¤ Author

**Chamith Shanaka Samarasinghe**
AI/ML Intern â€“ JW Infotech

---

## âœ… Final Note

This project demonstrates a **complete, realâ€‘world Multimodal RAG system**, from raw documents to an APIâ€‘based intelligent assistant, following industryâ€‘standard practices and modular design.
